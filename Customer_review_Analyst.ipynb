{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtsnBhSO1Sc5eP496/YJ6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalai2315/Langchain_for_AgentiAI/blob/main/Customer_review_Analyst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini project 3: Building a Customer Review Analyst"
      ],
      "metadata": {
        "id": "KX0VBVyCn4sT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Routing Chains in LCEL**\n",
        "\n",
        "A Routing Chain is a conditional logic mechanism that dynamically chooses which chain to run based on some property of the input or intermediate output."
      ],
      "metadata": {
        "id": "AH-ZzEVQopLX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNkphsRsnxV1",
        "outputId": "4572084c-e48d-4fa4-934c-b35a80d05341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "\n",
        "%pip install -U --quiet langchain langchain-google-genai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpcqS2J0oENb",
        "outputId": "a3286005-860f-4e1b-d5bc-81447b3aaf98"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash-latest\")"
      ],
      "metadata": {
        "id": "KX4S2-6yoJYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "BCIpt2uYoL3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\" Given the user instruction below for analysing customer review\n",
        "    classify it as only one of the categories:\n",
        "      - summarize\n",
        "      - sentimental\n",
        "      -email\n",
        "\n",
        "    Do not respond with more than one word\n",
        "\n",
        "    Instruction: {instruction}\n",
        "\"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "classifier_chain = classifier_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "s7tA7YGvoSSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\" Act as a customer review analyst, given the following customer review:\n",
        "        generate short summary(max 2 lines) of the review\n",
        "\n",
        "        customer review: {review}\n",
        "    \"\"\")\n",
        "\n",
        "summary_chain = summary_prompt | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "1fP4kx1DqkZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\" Act as a customer review analyst, given the following customer review:\n",
        "        find out the sentiment of the review, either positive, negative or neutral\n",
        "        return only one word, either positive, negative or neutral\n",
        "\n",
        "        customer review: {review}\n",
        "    \"\"\")\n",
        "\n",
        "sentiment_chain = sentiment_prompt | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "kD8EL0aEsRQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\" Act as a customer review analyst, given the following customer review and sentiment\n",
        "        generate an email response to the customer based on the following condition.\n",
        "        If the sentiment is positive or neutral, thank them for the review\n",
        "        If the sentiment is negative, apologize and suggest that they can improve their review\n",
        "\n",
        "        sentiment: {sentiment}\n",
        "\n",
        "        customer review: {review}\n",
        "        sentiment: {sentiment}\n",
        "    \"\"\")\n",
        "\n",
        "email_chain = email_prompt | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "JCyMI4g3srtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def default_answer(query):\n",
        "  return \"sorry instructions are not the defined intents\""
      ],
      "metadata": {
        "id": "Pi9QwPPntodN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableBranch\n",
        "\n",
        "branch = RunnableBranch(\n",
        "    (lambda x: \"summarize\" in x[\"topic\"].lower(), summary_chain),\n",
        "    (lambda x: \"sentimental\" in x[\"topic\"].lower(), sentiment_chain),\n",
        "    (lambda x: \"email\" in x[\"topic\"].lower(), email_chain),\n",
        "    default_answer\n",
        ")"
      ],
      "metadata": {
        "id": "rHQ4vsNRuLx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain = ({\"topic\" : classifier_chain,\n",
        "               \"instructions\": lambda input_prompt: input_prompt.get(\"instruction\"),\n",
        "               \"review\": lambda input_prompt: input_prompt.get(\"review\"),\n",
        "               \"sentiment\": lambda input_prompt: input_prompt.get(\"sentiment\"),\n",
        "               }\n",
        "              | branch)\n",
        "\n"
      ],
      "metadata": {
        "id": "g5Xtod3ouwYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_review = \"\"\"\n",
        "          Required a stylish lamp for my office space, and this particular one came with added storage at a reasonable price.\n",
        "          The delivery was surprisingly quick, arriving within just two days.\n",
        "          However, the pull string for the lamp suffered damage during transit.\n",
        "          To my relief, the company promptly dispatched a replacement, which arrived within a few days. Assembly was a breeze.\n",
        "          Then, I encountered an issue with a missing component, but their support team responded swiftly and provided the missing part.\n",
        "          It appears to be a commendable company that genuinely values its customers and the quality of its products.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Wm1ruqv7woPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = full_chain.invoke({\"instruction\": \"Generate a summary for the given review\",\n",
        "                             \"review\": sample_review})\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lUTGJbX1xBX6",
        "outputId": "313a6d2d-df70-4e15-8701-d90d58415261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stylish lamp with convenient storage arrived quickly, despite initial damage to the pull string and a missing component.  Excellent customer service ensured prompt replacements and resolution of all issues.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = full_chain.invoke({\"instruction\": \"Find out the sentiment of the customer for the given review\",\n",
        "                             \"review\": sample_review})\n",
        "sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oXZYAtzbxSFc",
        "outputId": "52137875-45bb-47cc-a213-3758ea407b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email_response = full_chain.invoke({\"instruction\": \"Write an email for the given customer review\",\n",
        "                             \"review\": sample_review,\n",
        "                               \"sentiment\": sentiment})\n",
        "print(email_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSulrmWHzDdq",
        "outputId": "873645ed-869f-45b0-bbc3-993387b3e86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Thank you for your feedback!\n",
            "\n",
            "Dear [Customer Name],\n",
            "\n",
            "Thank you so much for taking the time to leave such a positive review! We're thrilled to hear you love your new lamp and appreciate your kind words about our product, delivery speed, and customer support.\n",
            "\n",
            "We're especially glad that we were able to resolve the issues you experienced with the pull string and missing component so quickly.  We strive to provide excellent customer service and are delighted that we met your expectations in this instance.\n",
            "\n",
            "Your feedback is invaluable to us, and we appreciate you sharing your experience.  We hope you enjoy your stylish and functional new lamp for many years to come!\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "The [Company Name] Team\n"
          ]
        }
      ]
    }
  ]
}